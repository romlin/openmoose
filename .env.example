# ╔══════════════════════════════════════════════════╗
# ║           OpenMoose Configuration                ║
# ║   Copy to .env and fill in your values:          ║
# ║     cp .env.example .env                         ║
# ╚══════════════════════════════════════════════════╝

# ── Gateway ──────────────────────────────────────────
# Port for the HTTP/WebSocket server
GATEWAY_PORT=18789

# ── LLM Provider ────────────────────────────────────
# Which backend to use: 'ollama' (local) or 'mistral' (cloud)
LLM_PROVIDER=ollama

# ── Ollama (Local) ──────────────────────────────────
# Only used when LLM_PROVIDER=ollama
OLLAMA_HOST=http://127.0.0.1:11434
OLLAMA_MODEL=ministral-3:3b

# ── Mistral AI (Cloud) ─────────────────────────────
# Only used when LLM_PROVIDER=mistral
MISTRAL_MODEL=mistral-large-latest
MISTRAL_API_KEY=

# ── Text-to-Speech ──────────────────────────────────
# Language: en, ko, es, pt, fr
TTS_LANG=en
# Inference steps (lower = faster, 2 is a good default)
TTS_STEPS=4
# Playback speed multiplier (1.0 = normal)
TTS_SPEED=1.05

# ── Memory ──────────────────────────────────────────
# Path to the LanceDB vector database
MEMORY_DB_PATH=.moose/memory

# ── Browser Sandbox ─────────────────────────────────
# Custom directory for browser profiles (optional, defaults to .moose/data/browser-profiles)
# BROWSER_PROFILE_DIR=

# ── Logging ─────────────────────────────────────────
# Level: debug, info, warn, error
LOG_LEVEL=info
# Set to 'true' to suppress all console output
LOG_SILENT=false
